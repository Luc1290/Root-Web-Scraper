import express from "express";
import { chromium } from "playwright";

const app = express();
app.use(express.json());

app.post("/scrape", async (req, res) => {
  const { query } = req.body;

  console.log(`[SCRAPER] üîç Requ√™te re√ßue pour : "${query}"`);

  const browser = await chromium.launch({ headless: true });
  const page = await browser.newPage();

  try {
    const searchUrl = `https://search.brave.com/search?q=${encodeURIComponent(query)}`;
    console.log(`[SCRAPER] üîó Navigation vers Brave Search : ${searchUrl}`);
    await page.goto(searchUrl, { timeout: 20000 });

    console.log(`[SCRAPER] ‚úÖ Page Brave Search charg√©e`);
    const firstLinkSelector = 'a[href^="http"]:not([href*="brave.com"])';
    console.log(`[SCRAPER] üîé Attente du premier lien utile via le s√©lecteur : "${firstLinkSelector}"`);

    await page.waitForSelector(firstLinkSelector, { timeout: 10000 });

    const firstLink = await page.getAttribute(firstLinkSelector, "href");
    console.log(`[SCRAPER] üîó Premier lien r√©cup√©r√© : ${firstLink}`);

    console.log(`[SCRAPER] üåç Navigation vers le lien trouv√©`);
    await page.goto(firstLink, { timeout: 20000 });

    console.log(`[SCRAPER] ‚è≥ Petite pause pour laisser le DOM respirer`);
    await page.waitForTimeout(2000);

    // Extraction am√©lior√©e du contenu principal
    const content = await page.evaluate(() => {
      // Fonction pour calculer le score de contenu d'un √©l√©ment
      const getContentScore = (element) => {
        const text = element.innerText || "";
        const wordCount = text.split(/\s+/).length;
        const linkDensity = element.querySelectorAll('a').length / Math.max(wordCount, 1);
        
        // Les √©l√©ments avec beaucoup de texte et peu de liens sont probablement du contenu principal
        return wordCount * (1 - linkDensity);
      };

      // Identifier les √©l√©ments susceptibles de contenir du contenu principal
      const potentialElements = [
        // S√©lecteurs courants pour le contenu principal
        'article', 'main', '.content', '.post', '.article', 
        '.entry-content', '.post-content', '#content', '#main',
        '[role="main"]', '.main-content', '.page-content'
      ];

      // Trouver l'√©l√©ment avec le meilleur score
      let bestElement = document.body;
      let bestScore = getContentScore(document.body);

      // V√©rifier les √©l√©ments potentiels
      potentialElements.forEach(selector => {
        const elements = document.querySelectorAll(selector);
        elements.forEach(element => {
          const score = getContentScore(element);
          if (score > bestScore) {
            bestElement = element;
            bestScore = score;
          }
        });
      });

      // Si aucun √©l√©ment sp√©cifique n'a un bon score, essayer une autre approche
      if (bestElement === document.body) {
        // Trouver tous les paragraphes et leurs parents
        const paragraphs = Array.from(document.querySelectorAll('p'));
        const parents = {};
        
        paragraphs.forEach(p => {
          if (p.innerText.length > 50) { // Ignorer les paragraphes trop courts
            const parent = p.parentNode;
            parents[parent] = (parents[parent] || 0) + 1;
          }
        });
        
        // Trouver le parent avec le plus de paragraphes substantiels
        let maxParagraphs = 0;
        let bestParent = null;
        
        for (const [parent, count] of Object.entries(parents)) {
          if (count > maxParagraphs) {
            maxParagraphs = count;
            bestParent = parent;
          }
        }
        
        if (bestParent && maxParagraphs > 3) {
          bestElement = bestParent;
        }
      }

      // Extraire le titre de la page
      const title = document.title || "";
      
      // Extraire l'URL de la page
      const url = window.location.href;
      
      // Extraire le contenu principal
      const mainContent = bestElement.innerText || document.body.innerText;
      
      // Construire un r√©sultat structur√©
      return {
        title,
        url,
        content: mainContent,
        fullPageContent: document.body.innerText // Conserver le contenu complet aussi
      };
    });

    console.log(`[SCRAPER] üìÑ Contenu principal identifi√© et extrait`);
    console.log(`[SCRAPER] üìù Titre de la page: ${content.title}`);

    res.json(content);
  } catch (error) {
    console.error(`[SCRAPER] ‚ùå Erreur lors du scraping : ${error.message}`);
    res.status(500).json({ error: error.message });
  } finally {
    console.log(`[SCRAPER] üßπ Fermeture du navigateur...`);
    await browser.close();
    console.log(`[SCRAPER] ‚úÖ Navigateur ferm√© proprement`);
  }
});

// Endpoint pour r√©cup√©rer plusieurs r√©sultats
app.post("/scrape-multiple", async (req, res) => {
  const { query, numResults = 3 } = req.body;

  console.log(`[SCRAPER] üîç Requ√™te multiple re√ßue pour : "${query}" (${numResults} r√©sultats)`);

  const browser = await chromium.launch({ headless: true });
  const page = await browser.newPage();

  try {
    const searchUrl = `https://search.brave.com/search?q=${encodeURIComponent(query)}`;
    console.log(`[SCRAPER] üîó Navigation vers Brave Search : ${searchUrl}`);
    await page.goto(searchUrl, { timeout: 20000 });

    console.log(`[SCRAPER] ‚úÖ Page Brave Search charg√©e`);
    const linkSelector = 'a[href^="http"]:not([href*="brave.com"])';
    console.log(`[SCRAPER] üîé Recherche des ${numResults} premiers liens`);

    await page.waitForSelector(linkSelector, { timeout: 10000 });

    // R√©cup√©rer plusieurs liens
    const links = await page.evaluate((selector, max) => {
      const elements = document.querySelectorAll(selector);
      const urls = [];
      
      for (let i = 0; i < elements.length && urls.length < max; i++) {
        const href = elements[i].getAttribute('href');
        if (href && !urls.includes(href)) {
          urls.push(href);
        }
      }
      
      return urls;
    }, linkSelector, numResults);

    console.log(`[SCRAPER] üîó ${links.length} liens r√©cup√©r√©s`);

    // Visiter chaque lien et extraire le contenu
    const results = [];
    for (let i = 0; i < links.length; i++) {
      try {
        console.log(`[SCRAPER] üåç Navigation vers le lien ${i+1}/${links.length}: ${links[i]}`);
        await page.goto(links[i], { timeout: 20000 });
        await page.waitForTimeout(2000);

        const content = await page.evaluate(() => {
          // [M√™me logique d'extraction que dans l'endpoint /scrape]
          // (Code d'extraction du contenu principal identique √† celui ci-dessus)
          
          const title = document.title || "";
          const url = window.location.href;
          const mainContent = document.body.innerText;
          
          return { title, url, content: mainContent };
        });

        results.push({
          title: content.title,
          url: links[i],
          content: content.content.substring(0, 5000) // Limiter la taille pour √©viter des r√©ponses trop volumineuses
        });

        console.log(`[SCRAPER] ‚úÖ Contenu extrait du lien ${i+1}`);
      } catch (error) {
        console.error(`[SCRAPER] ‚ö†Ô∏è Erreur sur le lien ${i+1}: ${error.message}`);
        // Continuer avec le lien suivant m√™me en cas d'erreur
      }
    }

    res.json({ results });
  } catch (error) {
    console.error(`[SCRAPER] ‚ùå Erreur globale : ${error.message}`);
    res.status(500).json({ error: error.message });
  } finally {
    console.log(`[SCRAPER] üßπ Fermeture du navigateur...`);
    await browser.close();
    console.log(`[SCRAPER] ‚úÖ Navigateur ferm√© proprement`);
  }
});

const port = process.env.PORT || 5123;
app.listen(port, () => {
  console.log(`‚úÖ WebScraper am√©lior√© en ligne sur port ${port}`);
});